{"n_dim": 89, "n_trials": 340, "objective": "ackley_on_cube", "white": "bobyqa_default", "black": "dlib_default", "traceback": ["passing", "Traceback (most recent call last):\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.7/site-packages/humpday/comparison/eloratings.py\", line 79, in optimizer_game\n    with_count=True)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.7/site-packages/humpday/optimizers/dlibcube.py\", line 28, in dlib_default_cube\n    best_x, best_val = find_min_global(_objective, lb, ub, n_trials)\nRuntimeError: \n\nError detected at line 63.\nError detected in file /private/var/folders/g2/6p5lz9hn36vbnv165bk7yj7r0000gn/T/pip-install-ojjogyqk/dlib_836e2179ea074a8ba6ce68fbb0be6025/tools/python/src/global_optimization.cpp.\nError detected in function double call_func(py::object, const matrix<double, 0, 1> &).\n\nFailing expression was 0 < num && num < 35.\nFunctions being optimized must take between 1 and 35 scalar arguments.\n\n"], "best_val": [0.9284457930718684, null], "best_x": [[0.38417429297738703, 0.48822811376145464, 0.4882279049945277, 0.48822802150700084, 0.4882267270834574, 0.4882286048665551, 0.48822484314687825, 0.48822861782666216, 0.4882277755484252, 0.4882284307134064, 0.4882276955884595, 0.48822819584603994, 0.48822707014989114, 0.4882299404975941, 0.4882310044677779, 0.4882288744332538, 0.5030778392828921, 0.4882294938444694, 0.48822748054481996, 0.4882293400799071, 0.48822836619219234, 0.4882281885516944, 0.4882247503846939, 0.4882267094745164, 0.4882273107315815, 0.48822693734598666, 0.48822782089090494, 0.4882249267247662, 0.48776221871347614, 0.48822476838084156, 0.48822392484396193, 0.4882239274910892, 0.4882224166110918, 0.4882255103355879, 0.4882271444523866, 0.48822665836497736, 0.48822520827283267, 0.4882274944856109, 0.4882253869901718, 0.4882229205607321, 0.4885608551323457, 0.4882249396190267, 0.4882239906846783, 0.48822468117256984, 0.48822294078811057, 0.4882242713360174, 0.4882240109863511, 0.4882241966413747, 0.48821958699162443, 0.488225520761085, 0.48822540928244773, 0.4882248063003214, 0.4882246339659182, 0.4882259453114608, 0.48822584413635106, 0.4882266872946009, 0.48822560667512876, 0.4882282980542577, 0.48822758103610414, 0.488226626989455, 0.4882277878204014, 0.48822735148859486, 0.48822890686997267, 0.4882283538661191, 0.4882244209700076, 0.48822587016431235, 0.4882271358779728, 0.4882251250022149, 0.48822658504795996, 0.4882270911966158, 0.48822740427727856, 0.4882275779921409, 0.4882281235513388, 0.488227382743744, 0.4882279472031053, 0.4882275022931724, 0.48822808460305217, 0.48822728729561193, 0.48822725818766105, 0.4882283307682897, 0.4882267231104879, 0.4882265317734241, 0.48822700015255044, 0.4882271622121054, 0.4882266889913558, 0.4882265862384973, 0.4882268058226696, 0.4933931783396499, 0.4894314488757076], null], "feval_count": [340, null], "n_trials_instructed": [340, 340], "passing": [true, false], "completed": false, "winner": "incomplete", "points": null}