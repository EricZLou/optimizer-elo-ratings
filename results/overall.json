{"name": ["shgo_slsqp_sobol_cube", "shgo_powell_sobol_cube", "shgo_nelder_sobol_cube", "scipy_slsqp_cube", "scipy_powell_cube", "scipy_nelder_cube", "scipy_lbfgsb_cube", "pysot_ei_cube", "pysot_lcb_cube", "pysot_random_cube", "pysot_srbf_cube", "pysot_dycors_cube", "ax_default_cube", "optuna_cmaes_cube", "optuna_tpe_cube", "optuna_random_cube", "optuna_random_cube_clone", "optuna_random_cube_clone_1", "optuna_random_cube_clone_2", "platypus_genetic_cube", "platypus_evolutionary_cube", "platypus_nsgaii_cube", "platypus_cmaes_cube", "platypus_gde3_cube", "platypus_ibea_cube", "platypus_moead_cube", "platypus_omopso_cube", "platypus_smpso_cube", "platypus_spea2_cube", "platypus_epsmoea_cube", "nevergrad_ngopt_cube", "nevergrad_ngopt4_cube", "nevergrad_ngopt8_cube", "nevergrad_de_cube", "nevergrad_portfolio_cube", "nevergrad_oneplus_cube", "nevergrad_hammersley_cube", "hyperopt_atpe_cube", "hyperopt_rand_cube", "hyperopt_tpe_cube", "pymoo_nelder_cube", "pymoo_nsga3_cube", "pymoo_unsga3_cube", "pymoo_pattern_cube", "pymoo_nsga2_cube", "skopt_gp_default_cube", "ultraopt_random_cube", "ultraopt_etpe_cube", "bayesopt_ucb_cube", "bayesopt_ei_cube", "bayesopt_poi_cube", "dlib_cube", "nlopt_direct_cube", "nlopt_ags_cube", "nlopt_esch_cube", "nlopt_isres_cube", "nlopt_crs2lm_cube", "nlopt_directr_cube", "nlopt_directo_cube", "ultraopt_forest_cube", "ultraopt_gbrt_cube", "dlib_default_cube", "nlopt_directl_cube", "bobyqa_default_cube", "bobyqa_noise_cube"], "count": [373, 334, 389, 786, 497, 941, 546, 535, 566, 566, 540, 618, 557, 628, 1091, 1135, 1139, 1166, 1130, 814, 785, 826, 369, 836, 781, 1167, 844, 828, 823, 801, 1125, 1150, 1154, 1175, 1130, 1154, 1148, 1141, 1141, 1178, 946, 1138, 2016, 965, 784, 577, 1132, 1178, 526, 575, 532, 898, 1033, 456, 1006, 1020, 1068, 950, 872, 877, 367, 749, 866, 909, 959], "rating": [2039.788724814292, 2039.9374773153356, 2079.4069351375824, 1919.901164007975, 2139.0324992904166, 1907.331847848169, 1947.8348970912061, 2252.0737668709085, 2121.864228939121, 1262.5549278395624, 2638.209943490525, 2633.228838266416, 2553.5003535264495, 2157.544633086245, 2326.2103973718536, 1600, 1600, 1600, 1600, 1343.3589457885314, 1564.0147584720075, 1485.9977608470822, 1332.6096269125153, 1240.3137813507205, 1667.9326274291222, 1227.965647512241, 1690.6742269801512, 1313.8980371028879, 1195.2042638935197, 1749.748723724507, 2642.4190546832783, 2705.327897393077, 2571.691440876351, 1582.2526002341644, 1578.420167520681, 2769.8866146288105, 1911.9060231033454, 1872.2075396331284, 1905.381656005376, 2018.8799574420518, 1723.3292682504011, 1457.022355748556, 1556.7019122525885, 2305.2546740948496, 1347.3362308135804, 2528.978280177903, 1203.011737957848, 2292.0002650088813, 2244.50544801723, 2356.857625449926, 2327.279025380234, 2531.9104517747796, 1733.6384007689542, 2101.0127885473503, 1944.9069816744914, 1306.5753640195417, 1479.570097872401, 2616.6141736313284, 1074.9306977812362, 2168.167241074442, 2188.806105674532, 2428.2334103894577, 1672.729124894808, 2712.9039879113184, 2586.3201854493286], "traceback": ["passing", "passing", "passing", "Black took 57 function evals when instructed to use 131", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 551 function evals when instructed to use 551", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 552 function evals when instructed to use 551", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 214 function evals when instructed to use 211", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Traceback (most recent call last):\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.7/site-packages/humpday/comparison/eloratings.py\", line 43, in optimizer_game\n    with_count=True)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.7/site-packages/humpday/optimizers/dlibcube.py\", line 33, in dlib_cube\n    return dlib_default_cube(objective=objective, n_trials=n_trials, n_dim=n_dim, with_count=with_count)  # It is useful to have a clone of one of the better algos\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.7/site-packages/humpday/optimizers/dlibcube.py\", line 28, in dlib_default_cube\n    best_x, best_val = find_min_global(_objective, lb, ub, n_trials)\nRuntimeError: \n\nError detected at line 63.\nError detected in file /private/var/folders/g2/6p5lz9hn36vbnv165bk7yj7r0000gn/T/pip-install-ojjogyqk/dlib_836e2179ea074a8ba6ce68fbb0be6025/tools/python/src/global_optimization.cpp.\nError detected in function double call_func(py::object, const matrix<double, 0, 1> &).\n\nFailing expression was 0 < num && num < 35.\nFunctions being optimized must take between 1 and 35 scalar arguments.\n\n", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Traceback (most recent call last):\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.7/site-packages/humpday/comparison/eloratings.py\", line 43, in optimizer_game\n    with_count=True)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.7/site-packages/humpday/optimizers/dlibcube.py\", line 28, in dlib_default_cube\n    best_x, best_val = find_min_global(_objective, lb, ub, n_trials)\nRuntimeError: \n\nError detected at line 63.\nError detected in file /private/var/folders/g2/6p5lz9hn36vbnv165bk7yj7r0000gn/T/pip-install-ojjogyqk/dlib_836e2179ea074a8ba6ce68fbb0be6025/tools/python/src/global_optimization.cpp.\nError detected in function double call_func(py::object, const matrix<double, 0, 1> &).\n\nFailing expression was 0 < num && num < 35.\nFunctions being optimized must take between 1 and 35 scalar arguments.\n\n", "Black took 81 function evals when instructed to use 81", "passing", "passing"], "active": [true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true]}