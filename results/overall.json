{"name": ["shgo_slsqp_sobol_cube", "shgo_powell_sobol_cube", "shgo_nelder_sobol_cube", "scipy_slsqp_cube", "scipy_powell_cube", "scipy_nelder_cube", "scipy_lbfgsb_cube", "pysot_ei_cube", "pysot_lcb_cube", "pysot_random_cube", "pysot_srbf_cube", "pysot_dycors_cube", "ax_default_cube", "optuna_cmaes_cube", "optuna_tpe_cube", "optuna_random_cube", "optuna_random_cube_clone", "optuna_random_cube_clone_1", "optuna_random_cube_clone_2", "platypus_genetic_cube", "platypus_evolutionary_cube", "platypus_nsgaii_cube", "platypus_cmaes_cube", "platypus_gde3_cube", "platypus_ibea_cube", "platypus_moead_cube", "platypus_omopso_cube", "platypus_smpso_cube", "platypus_spea2_cube", "platypus_epsmoea_cube", "nevergrad_ngopt_cube", "nevergrad_ngopt4_cube", "nevergrad_ngopt8_cube", "nevergrad_de_cube", "nevergrad_portfolio_cube", "nevergrad_oneplus_cube", "nevergrad_hammersley_cube", "hyperopt_atpe_cube", "hyperopt_rand_cube", "hyperopt_tpe_cube", "pymoo_nelder_cube", "pymoo_nsga3_cube", "pymoo_unsga3_cube", "pymoo_pattern_cube", "pymoo_nsga2_cube", "skopt_gp_default_cube", "ultraopt_random_cube", "ultraopt_etpe_cube", "bayesopt_ucb_cube", "bayesopt_ei_cube", "bayesopt_poi_cube", "dlib_cube", "nlopt_direct_cube", "nlopt_ags_cube", "nlopt_esch_cube", "nlopt_isres_cube", "nlopt_crs2lm_cube", "nlopt_directr_cube", "nlopt_directo_cube", "ultraopt_forest_cube", "ultraopt_gbrt_cube", "dlib_default_cube", "nlopt_directl_cube", "bobyqa_default_cube", "bobyqa_noise_cube"], "count": [260, 233, 255, 294, 283, 362, 285, 323, 362, 358, 344, 396, 354, 420, 357, 364, 384, 413, 381, 197, 204, 198, 223, 192, 223, 360, 232, 213, 222, 186, 364, 377, 363, 381, 357, 368, 391, 368, 379, 374, 361, 392, 510, 373, 200, 385, 357, 389, 327, 383, 359, 368, 238, 249, 243, 232, 269, 224, 224, 169, 156, 178, 133, 138, 153], "rating": [1919.5047433441719, 1991.7654903117723, 2041.2246109445946, 1569.7220503568933, 2155.531233683624, 1154.4548274417195, 1796.358172434394, 1730.5032574622307, 1802.4066650151442, 1433.228754888935, 2170.0315783118913, 2052.205749130595, 2211.7086522413, 2057.1735118897436, 1775.575762102795, 1600, 1600, 1600, 1600, 1080.1818315076305, 1177.6577261217617, 1298.8755225170753, 1360.7035222847815, 1317.3976713368766, 1173.912587218825, 1489.0906029076493, 1541.847226427777, 1315.2144075801377, 1159.6926553485473, 1154.2800252945915, 2108.9225744258274, 2021.4887511204417, 2049.4214671109326, 1368.690180719245, 1435.3585917287799, 1610.1114787744477, 1266.2983442072896, 1568.4622686105174, 1775.8925223272408, 1655.2745628523444, 2072.901424367748, 1801.2083180450186, 1862.4483571869532, 2236.7217746464707, 1189.4614881389857, 2179.033970390674, 1201.9280099874732, 1732.9431083173147, 1749.6614039728051, 1871.7779309884713, 1768.6456072158549, 2205.0582901303355, 2077.2690449836687, 1509.860779639917, 1498.5872544217355, 1570.113950429184, 1699.4041918714395, 2203.852505346084, 1913.9748304682842, 1778.6978412089288, 1756.1078586822252, 2196.407772711675, 2136.244249349244, 2272.1481670104768, 2297.548977741596], "traceback": ["passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 88 function evals when instructed to use 88", "passing", "passing", "Black took 82 function evals when instructed to use 82", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Traceback (most recent call last):\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.7/site-packages/humpday/comparison/eloratings.py\", line 43, in optimizer_game\n    with_count=True)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.7/site-packages/humpday/optimizers/ultraoptcube.py\", line 47, in ultraopt_gbrt_cube\n    method='GBRT')\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.7/site-packages/humpday/optimizers/ultraoptcube.py\", line 31, in ultraopt_cube_factory\n    n_jobs=1, show_progressbar=False, parallel_strategy=\"Serial\" )\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.7/site-packages/ultraopt/facade/fmin.py\", line 106, in fmin\n    opt_.tell(config, loss)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.7/site-packages/ultraopt/optimizer/base_opt.py\", line 63, in tell\n    self.new_result(job, update_model=update_model)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.7/site-packages/ultraopt/optimizer/base_opt.py\", line 101, in new_result\n    self._new_result(budget, vectors, losses)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.7/site-packages/ultraopt/optimizer/bo/sampling_sort_opt.py\", line 72, in _new_result\n    y_obvs = self.loss_transformer.fit_transform(losses)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.7/site-packages/ultraopt/utils/loss_transformer.py\", line 41, in fit_transform\n    y = super(LogScaledLossTransformer, self).fit_transform(y)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.7/site-packages/ultraopt/utils/loss_transformer.py\", line 17, in fit_transform\n    y[y >= ERR_LOSS] = y[y < ERR_LOSS].max() + 0.1\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.7/site-packages/numpy/core/_methods.py\", line 39, in _amax\n    return umr_maximum(a, axis, None, out, keepdims, initial, where)\nValueError: zero-size array to reduction operation maximum which has no identity\n", "passing", "passing", "passing", "Black took 44 function evals when instructed to use 131"], "active": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true]}